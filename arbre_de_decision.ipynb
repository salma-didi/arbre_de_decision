{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c14a73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from math import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9c6ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame([[14000, 20250, 2, 1],\n",
    "                         [15000, 20000, 3, 0],\n",
    "                         [10000, 10250, 2, 1],\n",
    "                         [20000, 20250, 3, 0],\n",
    "                         [22000, 20000, 4, 1],\n",
    "                         [12000, 10250, 2, 1],\n",
    "                         [19800, 30250, 3, 0],\n",
    "                         [13000, 14000, 2, 0],\n",
    "                         [14000, 30250, 3, 0],\n",
    "                         [19000, 23250, 2, 1],\n",
    "                         [17000, 65000, 4, 1],\n",
    "                         [9000, 30250, 2, 0]],\n",
    "                      columns=['montant','code_postale','nb_operations','fraude'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f4c4376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>montant</th>\n",
       "      <th>code_postale</th>\n",
       "      <th>nb_operations</th>\n",
       "      <th>fraude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14000</td>\n",
       "      <td>20250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15000</td>\n",
       "      <td>20000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>10250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>20250</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22000</td>\n",
       "      <td>20000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12000</td>\n",
       "      <td>10250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19800</td>\n",
       "      <td>30250</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13000</td>\n",
       "      <td>14000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14000</td>\n",
       "      <td>30250</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19000</td>\n",
       "      <td>23250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17000</td>\n",
       "      <td>65000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9000</td>\n",
       "      <td>30250</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    montant  code_postale  nb_operations  fraude\n",
       "0     14000         20250              2       1\n",
       "1     15000         20000              3       0\n",
       "2     10000         10250              2       1\n",
       "3     20000         20250              3       0\n",
       "4     22000         20000              4       1\n",
       "5     12000         10250              2       1\n",
       "6     19800         30250              3       0\n",
       "7     13000         14000              2       0\n",
       "8     14000         30250              3       0\n",
       "9     19000         23250              2       1\n",
       "10    17000         65000              4       1\n",
       "11     9000         30250              2       0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "821abe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree_regressor:\n",
    "    #cette classe contient toutes les fonctions'''\n",
    "    def __init__(self,target,dataframe):\n",
    "        #cette fonction est pout initialiser les variables\n",
    "        #target:la variable cible à classifier\n",
    "        #dataframe:les données d'appraentissage\n",
    "        self.target=target\n",
    "        self.dataframe=dataframe\n",
    "        \n",
    "    def quantitative_split(self,feature,value,dataset):\n",
    "        #cette fonction divise les données en focntion de valeur value de la variable quatitative feature\n",
    "        ''''\n",
    "        INPUT:\n",
    "            feature:integer correspond à la variable à séparer\n",
    "            value:integer correspond à la valeur à laquelle séparer\n",
    "        OUTPUT:\n",
    "            left:dataframe avec les données ou featue est plus petie ou égale à value\n",
    "            right:dataframe avec les données ou featue est plus grande à value\n",
    "        '''\n",
    "        left=dataset[dataset.loc[:,feature]<=value]\n",
    "        right=dataset[dataset.loc[:,feature]>value]\n",
    "        \n",
    "        return left,right\n",
    "    \n",
    "    def qualitative_split(self,feature,value,dataset):\n",
    "        #cette fonction divise les données en focntion de valeur 'value' de la variable qualitative 'feature'\n",
    "        '''\n",
    "        INPUT:\n",
    "            feature:integer correspond à la variable à séparer\n",
    "            value:integer correspond à la valeur à laquelle séparer\n",
    "        OUTPUT:\n",
    "            left:dataframe avec les données ou featue est égale à value\n",
    "            right:dataframe avec les données ou featue est différentde de value\n",
    "        '''\n",
    "        left=dataset[dataset.loc[:,feature]==value]\n",
    "        right=dataset[dataset.loc[:,feature]!=value]\n",
    "        \n",
    "        return left,right\n",
    "    \n",
    "    def entropy(self,dataset):\n",
    "        #cette fonction calcule l'entropy \n",
    "        rows=dataset[self.target]\n",
    "        #calcule le nombre de valeur distincts\n",
    "        counts = Counter(rows)\n",
    "        # Calcule l'entropy \n",
    "        entropy = 0\n",
    "        for count in counts.values():\n",
    "            p = count / len(dataset)\n",
    "            entropy -= p * (log(p)/log(2))\n",
    "        return entropy\n",
    "   \n",
    "\n",
    "    def split_evaluator(self,left_dataset,right_dataset):\n",
    "        #calculer le cout de séparation de noeud en deux branches\n",
    "        '''\n",
    "        INPUT:\n",
    "            left_dataset:dataset de la branche de gauche\n",
    "            right_dataset:dataset de la branche de droite\n",
    "        OUTPUT:\n",
    "            cost:cout de la séparation\n",
    "        '''\n",
    "        left_eval=self.entropy(left_dataset)\n",
    "        nb_left=left_dataset.shape[0]\n",
    "        right_eval=self.entropy(right_dataset)\n",
    "        nb_right=right_dataset.shape[0]\n",
    "        nb_total=nb_left+nb_right\n",
    "        cost=nb_left/nb_total * left_eval + nb_right/nb_total * right_eval\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def test_qualitative(self, dataset, feature):\n",
    "        #tester toutes les séparations possibles d'une variable qualitative\n",
    "        '''\n",
    "        INPUT \n",
    "           - dataset : dataset à évaluer\n",
    "           - feature : variable du dataset à évaluer\n",
    "        OUTPUT\n",
    "           - df_eval : dataframe contenant le coût de chaque séparation\n",
    "        ''' \n",
    "        df_eval = pd.DataFrame([], columns=('feature', 'value', 'nature', 'cost'))\n",
    "        for value in dataset.loc[:, feature].unique() :\n",
    "            left, right = self.qualitative_split(feature, value, dataset)\n",
    "            cost_result = self.split_evaluator(left, right)\n",
    "            df_eval = pd.concat([df_eval,pd.DataFrame([[feature, value,'qualitative',cost_result]],columns=('feature', 'value', 'nature', 'cost'))])\n",
    "            \n",
    "        return df_eval\n",
    "      \n",
    "        \n",
    "    def test_quantitative(self, dataset, feature):\n",
    "        #Tester toutes les séparations possibles d'une variable quantitative\n",
    "        '''\n",
    "        INPUT \n",
    "            - dataset : dataset à évaluer\n",
    "            - feature : variable du dataset à évaluer\n",
    "        OUTPUT \n",
    "           - df_eval : dataframe contenant le coût de chaque séparation\n",
    "        '''\n",
    "        df_eval = pd.DataFrame([], columns=('feature', 'value', 'nature', 'cost'))\n",
    "        for value in dataset.loc[:, feature].unique()  : \n",
    "            left, right = self.quantitative_split(feature, value, dataset)\n",
    "            cost_result = self.split_evaluator(left, right)\n",
    "            df_eval = pd.concat([df_eval,pd.DataFrame([[feature, value,'quantitative',cost_result]],columns=('feature', 'value', 'nature', 'cost'))])\n",
    "        return df_eval\n",
    "    \n",
    "    \n",
    "    def find_best_split(self, dataset):\n",
    "        #Trouver la meilleure séparation\n",
    "        '''\n",
    "        INPUT \n",
    "           - dataset : jeu de données à séparer\n",
    "        OUTPUT \n",
    "           - def_eval : dataset contenant: \n",
    "               'feature' variable à séparer\n",
    "               'value' la valeur à laquelle séparer la variable\n",
    "               'nature' la nature de la variable \n",
    "               'cost' le coût de cette séparation\n",
    "        '''\n",
    "        df_eval = pd.DataFrame([], columns=('feature', 'value', 'nature', 'cost'))\n",
    "        columns = dataset.columns[np.logical_not(dataset.columns == self.target)]\n",
    "        for column in columns : \n",
    "            if len(dataset[column].unique()) >= 3 :\n",
    "                df_eval = pd.concat([df_eval,self.test_quantitative(dataset, column)])\n",
    "            elif len(dataset[column].unique()) == 2 :\n",
    "                df_eval = pd.concat([df_eval,self.test_qualitative(dataset, column)])\n",
    "\n",
    "        df_eval = df_eval.reset_index(drop=True)\n",
    "        \n",
    "        #index du feature qui le cout minimum\n",
    "        idx_cost_min = df_eval['cost'].idxmin(axis=0, skipna=True)\n",
    "\n",
    "        return df_eval.iloc[idx_cost_min, :]\n",
    "    \n",
    "    \n",
    " \n",
    "    def create_feuille(self, dataset):\n",
    "        #Création d'une feuille \n",
    "        '''\n",
    "        INPUT \n",
    "           - dataset : dataset de la feuille à construire\n",
    "        OUTPUT \n",
    "           - feuille : la classe feuille créée avec les informations de notre dataset\n",
    "        ''' \n",
    "        labels = dataset[self.target]        \n",
    "        prediction = np.mean(labels)\n",
    "\n",
    "        return feuille(dataset, prediction)\n",
    "    \n",
    "    def training(self, dataset):\n",
    "        #Cette fonction va construire l'arbre de décision en fonction des paramètres fournir à l'initialisation de cette classe.\n",
    "        \n",
    "      \n",
    "        # Si le dataset est pure nous créons une feuille\n",
    "        if len(dataset[self.target].unique())==1 :\n",
    "            return self.create_feuille(dataset)\n",
    "\n",
    "        # Recherche de la meilleur séparation\n",
    "        split_eval = self.find_best_split(dataset)\n",
    "        # Si le coût obtenu après séparation est moins bon que le coût actuel,création d'une feuille avec le dataset actuel\n",
    "        if split_eval['cost'] >= self.entropy(dataset) :\n",
    "            return self.create_feuille(dataset)\n",
    "      \n",
    "\n",
    "        # Séparation du dataset selon la nature de la variable choisie\n",
    "        if split_eval['nature'] == 'qualitative' :\n",
    "            left_branch, right_branch = self.qualitative_split(split_eval['feature'], split_eval['value'], dataset)\n",
    "        elif split_eval['nature'] == 'quantitative' :\n",
    "            left_branch, right_branch = self.quantitative_split(split_eval['feature'], split_eval['value'], dataset)\n",
    "\n",
    "        # Entraînement récursif de la branche de gauche\n",
    "        left_node = self.training(left_branch)\n",
    "\n",
    "        # Entraînement récrusif de la branche de droite\n",
    "        right_node = self.training(right_branch)\n",
    "        \n",
    "        \n",
    "        # On retourne la racine de l'arbre\n",
    "        return neoud(split_eval['feature'], \n",
    "                  split_eval['value'], \n",
    "                  split_eval['cost'], \n",
    "                  split_eval['nature'],\n",
    "                  left_node,\n",
    "                  right_node)\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb6e77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neoud:\n",
    "    #Cette classe a pour but de représenter les branches de notre arbre de regression\n",
    "    def __init__(self, feature, value, cost, nature, left_branch, right_branch):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.nature = nature\n",
    "        self.left_branch = left_branch\n",
    "        self.right_branch = right_branch\n",
    "\n",
    "    def __split__(self):\n",
    "        if self.nature == 'quantitative' :\n",
    "            return self.feature + ' <= ' + str(self.value)\n",
    "        elif self.nature == 'qualitative' :\n",
    "            return self.feature + ' == ' + str(self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1013017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(neoud, spacing=\"\"):\n",
    "    #Affichage de l'arbre de décision\n",
    "    '''\n",
    "    INPUT \n",
    "     - node : branche à afficher\n",
    "     - spacings : espace à afficher en fonction de la profondeur de la branche\n",
    "    '''\n",
    "\n",
    "    # Différents affichages si c'est une feuille \n",
    "    #vérifier si le neoud est une classe finale=feuille\n",
    "    if isinstance(neoud, feuille):\n",
    "        print (spacing + \"Prediction\", neoud.prediction)\n",
    "        return\n",
    "\n",
    "    # Affichage de la condition de la séparation\n",
    "    print (spacing + neoud.__split__())\n",
    "\n",
    "    # Dans le cas où la condition est vérifiée\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(neoud.left_branch, spacing + \"  \")\n",
    "\n",
    "    # Dans le cas où la condition n'est pas vérifiée\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(neoud.right_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a49a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feuille:\n",
    "    #Cette classe a pour but de représenter les feuilles de l'arbre\n",
    "    def __init__(self, dataset, prediction):\n",
    "        self.dataset = dataset\n",
    "        self.prediction = prediction\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "17dcd957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_postale <= 10250\n",
      "--> True:\n",
      "  Prediction 1.0\n",
      "--> False:\n",
      "  nb_operations <= 3\n",
      "  --> True:\n",
      "    nb_operations == 2\n",
      "    --> True:\n",
      "      montant <= 13000\n",
      "      --> True:\n",
      "        Prediction 0.0\n",
      "      --> False:\n",
      "        Prediction 1.0\n",
      "    --> False:\n",
      "      Prediction 0.0\n",
      "  --> False:\n",
      "    Prediction 1.0\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_regressor('fraude', dataframe)\n",
    "tree_trained = tree.training(dataframe)\n",
    "print_tree(tree_trained)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea295a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
